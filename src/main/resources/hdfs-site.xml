<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!--
  Licensed under the Apache License, Version 2.0 (the "License");
  you may not use this file except in compliance with the License.
  You may obtain a copy of the License at

    http://www.apache.org/licenses/LICENSE-2.0

  Unless required by applicable law or agreed to in writing, software
  distributed under the License is distributed on an "AS IS" BASIS,
  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  See the License for the specific language governing permissions and
  limitations under the License. See accompanying LICENSE file.
-->

<!-- Put site-specific property overrides in this file. -->

<configuration>

    <property>
        <name>dfs.replication</name>
        <value>1</value>
    </property>

<!--新文件的默认块最小大小，以字节为单位。您可以使用以下后缀(不区分大小写):(k,m,g,t,p,e,指定尺寸(如128k, 512m, 1g等)，或提供完整的字节大小(如134217728表示128 MB)。-->
   
    <property>
	<name>dfs.blocksize</name>
	<value>5120000</value>
    </property>

<!-- dfs的namenode的webUI监听的ip和端口 -->

    <property>
	<name>dfs.namenode.http-address</name>Tip:关于0.0.0.0得ip地址的含义
	<value>0.0.0.0:50070</value>
    </property>

<!-- The secondary namenode的ip地址和端口 -->

    <property>
	<name>dfs.namenode.secondary.http-address</name>
	<value>0.0.0.0:50090</value>
    </property>

<!--确定DFS的namenode应该在本地文件系统的何处存储名称表(fsimage)如果这是一个以逗号分隔的目录列表，那么名称表将复制到所有目录中，以实现冗余。-->

    <property>
	<name>dfs.namenode.name.dir</name>
	<value>file:///home/apps/hadoop/hadoop-2.8.1/hdpdata/dfs/name</value>
	<final>true</final>
    </property>

<!--确定DFS的datanode应该将其块存储在本地文件系统的什么位置如果这是一个以逗号分隔的目录列表，那么数据将存储在所有命名的目录中，通常存储在不同的设备上。对于HDFS存储策略，应该用相应的存储类型([SSD]/[DISK]/[ARCHIVE]/[RAM_DISK])标记目录。如果目录没有显式标记存储类型，则默认存储类型为磁盘。如果本地文件系统权限允许，将创建不存在的目录。-->

    <property>
	<name>dfs.datanode.data.dir</name>
	<value>file:///home/apps/hadoop/hadoop-2.8.1/hdpdata/dfs/data</value>
    </property>

<!--确定DFS的secondary namenode应该在本地文件系统的何处存储要合并的临时映像如果这是一个以逗号分隔的目录列表，那么映像将复制到所有目录中以实现冗余。-->

    <property>
	<name>dfs.namenode.checkpoint.dir</name>
	<value>file:///home/apps/hadoop/hadoop-2.8.1/hdpdata/dfs/cname</value>
    </property>

<!--确定DFS的secondary namenode应该在本地文件系统的何处存储要合并的临时edit文件如果这是一个以逗号分隔的目录列表，那么编辑将复制到所有目录中以实现冗余。默认值与dfs.namenode.checkpoint.dir相同-->

    <property>
	<name>dfs.namenode.checkpoint.edits.dir</name>
	<value>file:///home/apps/hadoop/hadoop-2.8.1/hdpdata/dfs/cname</value>
    </property>

<!--开启在网页中使用hdfs-->

    <property>
	<name>dfs.webhdfs.enabled</name>
	<value>true</value>
    </property>
    
</configuration>
